{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MINST-Digit Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is for only training the model, testing model accuracy with hyperparameters, this is not for EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import os\n",
    "\n",
    "import torch.nn as nn   \n",
    "import torch.nn.functional as F\n",
    "from torchvision  import datasets \n",
    "from torch.utils.data import Dataset,DataLoader ,ConcatDataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import random_split, SubsetRandomSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is downloaded from Kaggle Dataset, link :https://www.kaggle.com/c/digit-recognizer/data <br>\n",
    "`train.csv` and `test.csv` are extracted to path `notebooks\\data` path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(\"notebooks\",\"data\",\"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(\"notebooks\",\"data\",\"test.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 4, 7, 3, 5, 8, 9, 2, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nrows = 3\n",
    "ncols = 4\n",
    "fig, axes = plt.subplots(nrows,ncols,figsize=(10,8))\n",
    "i=0\n",
    "\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        axes[row][col].imshow(train_df.iloc[i,1:].values.reshape(28,28),cmap='gray')\n",
    "        axes[row][col].set_title(train_df.iloc[i,0])\n",
    "        axes[row][col].axis('off')\n",
    "        i+=1\n",
    "\n",
    "plt.suptitle('Data Samples', fontsize=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetMNIST(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "                \n",
    "        image = item[1:].values.astype(np.uint8).reshape((28, 28))\n",
    "        label = item[0]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train: 35700\n",
      "Length valid: 6300\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "VALID_SIZE = 0.15 # percentage of data for validation\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "])\n",
    "\n",
    "# Creating datasets for training and validation\n",
    "train_data = DatasetMNIST(train_df, transform=transform_train)\n",
    "valid_data = DatasetMNIST(train_df, transform=transform_valid)\n",
    "\n",
    "# Shuffling data and choosing data that will be used for training and validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(VALID_SIZE * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE, sampler=valid_sampler)\n",
    "\n",
    "print(f\"Length train: {len(train_idx)}\")\n",
    "print(f\"Length valid: {len(valid_idx)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# As we are deploying on server that does not have GPU, setting use_cuda to default False, disbale model to use GPU\n",
    "use_cuda = False\n",
    "print(use_cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_channels =1 ,out_channels = 10):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(in_channels=in_channels,out_channels=8,kernel_size=3,stride =1,padding=2)\n",
    "        self.b1 = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.c2 = nn.Conv2d(in_channels = 8,out_channels=32,kernel_size=3,padding=2,stride=1)\n",
    "        self.b2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.c3 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=2)\n",
    "        self.b3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.l1 = nn.Linear(64*5*5,1024)\n",
    "        self.l2 = nn.Linear(1024,512)\n",
    "\n",
    "        self.l4 = nn.Linear(512,128)\n",
    "\n",
    "        self.l6 = nn.Linear(128,32)\n",
    "        self.final = nn.Linear(32,out_channels)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        nodes =F.relu(self.b1(self.c1(x)))\n",
    "        nodes = F.max_pool2d(nodes,2,2) # 1,14,14\n",
    "    \n",
    "        nodes = F.relu(self.b2(self.c2(nodes))) \n",
    "        nodes = F.max_pool2d(nodes,2,2) #1,8,8\n",
    "        nodes = F.dropout(nodes,0.3)\n",
    "        nodes = F.relu(self.b3(self.c3(nodes)))\n",
    "        nodes = F.max_pool2d(nodes,2,2) # 1,5,5\n",
    "        nodes = F.dropout(nodes,0.4)\n",
    "        nodes = F.relu(self.l1(nodes.reshape(-1,64*5*5)))\n",
    "        nodes = F.relu(self.l2(nodes))\n",
    "        # nodes = F.relu(self.l3(nodes))\n",
    "        nodes = F.dropout(nodes)\n",
    "        nodes = F.relu(self.l4(nodes))\n",
    "        nodes = self.final(F.relu(self.l6(nodes)))#F.relu(self.l5(nodes)))))\n",
    "        return nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net, self).__init__()\n",
    "        \n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, 3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.MaxPool2d(2, 2),\n",
    "#             nn.Dropout(0.25)\n",
    "#         )\n",
    "        \n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv2d(32, 64, 3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.Conv2d(64, 64, 3, stride=2, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.MaxPool2d(2, 2),\n",
    "#             nn.Dropout(0.25)\n",
    "#         )\n",
    "        \n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv2d(64, 128, 3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.MaxPool2d(2, 2),\n",
    "#             nn.Dropout(0.25)\n",
    "#         )\n",
    "        \n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(128, 10),\n",
    "#         )\n",
    "                \n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.conv3(x)\n",
    "        \n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (c1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (b1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (c2): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (b2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (c3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (b3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (l1): Linear(in_features=1600, out_features=1024, bias=True)\n",
      "  (l2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (l4): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (l6): Linear(in_features=128, out_features=32, bias=True)\n",
      "  (final): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n",
      "--------------------\n",
      "Total Number of Parameters : 2255466 \n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "print(model)\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_on_gpu = False\n",
    "\n",
    "size = 0\n",
    "for layer in model.parameters():\n",
    "    size +=torch.numel(layer)\n",
    "\n",
    "print(\"--------------------\\nTotal Number of Parameters :\",size,'\\n--------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def __call__(self, validation_loss):\n",
    "        if self.min_validation_loss>validation_loss :\n",
    "            # print(f\"Loss increased from {self.min_validation_loss:.5f} to {validation_loss:.5f}\")\n",
    "            print(\"Loss changed.\")\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif (self.min_validation_loss + self.min_delta)<=validation_loss:\n",
    "            # print(f\"Loss did not increase from {self.min_validation_loss:.5f} \")\n",
    "            print(\"No change in loss.\")\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_per_epoch(train_loader,model,optimizer,):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for data,label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out,label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+= loss.item()\n",
    "    return running_loss\n",
    "\n",
    "def test_per_epoch(valid_loader,model,):\n",
    "    valid_accuracy = 0\n",
    "    valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data,label in valid_loader:\n",
    "            out = model(data)\n",
    "            _,top_class = out.topk(1,dim=1)\n",
    "            equals = top_class == label.view(*top_class.shape)\n",
    "            valid_loss += criterion(out, label).item()\n",
    "            valid_accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "    model.train()\n",
    "    return valid_accuracy, valid_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 | Training Loss 2.30116  | Test Loss 2.30143 |  Accuracy 0.09492\n",
      "Loss changed.\n",
      "Epoch   2 | Training Loss 2.29916  | Test Loss 2.29830 |  Accuracy 0.09460\n",
      "Loss changed.\n",
      "Epoch   3 | Training Loss 2.29664  | Test Loss 2.29620 |  Accuracy 0.10127\n",
      "Loss changed.\n",
      "Epoch   4 | Training Loss 2.29352  | Test Loss 2.29288 |  Accuracy 0.11333\n",
      "Loss changed.\n",
      "Epoch   5 | Training Loss 2.29022  | Test Loss 2.28919 |  Accuracy 0.13127\n",
      "Loss changed.\n",
      "Epoch   6 | Training Loss 2.28618  | Test Loss 2.28484 |  Accuracy 0.14286\n",
      "Loss changed.\n",
      "Epoch   7 | Training Loss 2.28066  | Test Loss 2.27906 |  Accuracy 0.14762\n",
      "Loss changed.\n",
      "Epoch   8 | Training Loss 2.27443  | Test Loss 2.27222 |  Accuracy 0.15238\n",
      "Loss changed.\n",
      "Epoch   9 | Training Loss 2.26599  | Test Loss 2.26284 |  Accuracy 0.15159\n",
      "Loss changed.\n",
      "Epoch  10 | Training Loss 2.25450  | Test Loss 2.24958 |  Accuracy 0.15952\n",
      "Loss changed.\n",
      "Epoch  11 | Training Loss 2.24030  | Test Loss 2.23261 |  Accuracy 0.17635\n",
      "Loss changed.\n",
      "Epoch  12 | Training Loss 2.21881  | Test Loss 2.20901 |  Accuracy 0.20190\n",
      "Loss changed.\n",
      "Epoch  13 | Training Loss 2.18972  | Test Loss 2.17325 |  Accuracy 0.21905\n",
      "Loss changed.\n",
      "Epoch  14 | Training Loss 2.15000  | Test Loss 2.13182 |  Accuracy 0.25238\n",
      "Loss changed.\n",
      "Epoch  15 | Training Loss 2.10068  | Test Loss 2.07418 |  Accuracy 0.29254\n",
      "Loss changed.\n",
      "Epoch  16 | Training Loss 2.04347  | Test Loss 2.01898 |  Accuracy 0.33159\n",
      "Loss changed.\n",
      "Epoch  17 | Training Loss 1.97770  | Test Loss 1.94371 |  Accuracy 0.35841\n",
      "Loss changed.\n",
      "Epoch  18 | Training Loss 1.90066  | Test Loss 1.86399 |  Accuracy 0.38810\n",
      "Loss changed.\n",
      "Epoch  19 | Training Loss 1.80420  | Test Loss 1.74486 |  Accuracy 0.43730\n",
      "Loss changed.\n",
      "Epoch  20 | Training Loss 1.67484  | Test Loss 1.59751 |  Accuracy 0.51302\n",
      "Loss changed.\n",
      "Epoch  21 | Training Loss 1.50716  | Test Loss 1.41619 |  Accuracy 0.58190\n",
      "Loss changed.\n",
      "Epoch  22 | Training Loss 1.31448  | Test Loss 1.23086 |  Accuracy 0.64095\n",
      "Loss changed.\n",
      "Epoch  23 | Training Loss 1.13736  | Test Loss 1.06375 |  Accuracy 0.67143\n",
      "Loss changed.\n",
      "Epoch  24 | Training Loss 0.98861  | Test Loss 0.93166 |  Accuracy 0.70159\n",
      "Loss changed.\n",
      "Epoch  25 | Training Loss 0.87810  | Test Loss 0.82703 |  Accuracy 0.73667\n",
      "Loss changed.\n",
      "Epoch  26 | Training Loss 0.79468  | Test Loss 0.77385 |  Accuracy 0.75413\n",
      "Loss changed.\n",
      "Epoch  27 | Training Loss 0.72970  | Test Loss 0.71256 |  Accuracy 0.77571\n",
      "Loss changed.\n",
      "Epoch  28 | Training Loss 0.67754  | Test Loss 0.65019 |  Accuracy 0.78905\n",
      "Loss changed.\n",
      "Epoch  29 | Training Loss 0.63941  | Test Loss 0.62388 |  Accuracy 0.80048\n",
      "Loss changed.\n",
      "Epoch  30 | Training Loss 0.59629  | Test Loss 0.59631 |  Accuracy 0.80937\n",
      "Loss changed.\n",
      "Epoch  31 | Training Loss 0.56983  | Test Loss 0.55435 |  Accuracy 0.81952\n",
      "Loss changed.\n",
      "Epoch  32 | Training Loss 0.53588  | Test Loss 0.52653 |  Accuracy 0.83476\n",
      "Loss changed.\n",
      "Epoch  33 | Training Loss 0.51527  | Test Loss 0.49306 |  Accuracy 0.84079\n",
      "Loss changed.\n",
      "Epoch  34 | Training Loss 0.49412  | Test Loss 0.48304 |  Accuracy 0.84444\n",
      "Loss changed.\n",
      "Epoch  35 | Training Loss 0.47375  | Test Loss 0.45741 |  Accuracy 0.85508\n",
      "Loss changed.\n",
      "Epoch  36 | Training Loss 0.45322  | Test Loss 0.45680 |  Accuracy 0.85286\n",
      "Loss changed.\n",
      "Epoch  37 | Training Loss 0.43831  | Test Loss 0.43345 |  Accuracy 0.86571\n",
      "Loss changed.\n",
      "Epoch  38 | Training Loss 0.41905  | Test Loss 0.41085 |  Accuracy 0.86714\n",
      "Loss changed.\n",
      "Epoch  39 | Training Loss 0.40984  | Test Loss 0.40056 |  Accuracy 0.88000\n",
      "Loss changed.\n",
      "Epoch  40 | Training Loss 0.39700  | Test Loss 0.39184 |  Accuracy 0.88270\n",
      "Loss changed.\n",
      "Epoch  41 | Training Loss 0.38165  | Test Loss 0.37797 |  Accuracy 0.88048\n",
      "Loss changed.\n",
      "Epoch  42 | Training Loss 0.36954  | Test Loss 0.37706 |  Accuracy 0.88302\n",
      "Loss changed.\n",
      "Epoch  43 | Training Loss 0.36125  | Test Loss 0.36079 |  Accuracy 0.88873\n",
      "Loss changed.\n",
      "Epoch  44 | Training Loss 0.35068  | Test Loss 0.34879 |  Accuracy 0.89365\n",
      "Loss changed.\n",
      "Epoch  45 | Training Loss 0.33996  | Test Loss 0.34785 |  Accuracy 0.89651\n",
      "Loss changed.\n",
      "Epoch  46 | Training Loss 0.33219  | Test Loss 0.33442 |  Accuracy 0.89683\n",
      "Loss changed.\n",
      "Epoch  47 | Training Loss 0.32763  | Test Loss 0.32156 |  Accuracy 0.90063\n",
      "Loss changed.\n",
      "Epoch  48 | Training Loss 0.31768  | Test Loss 0.31076 |  Accuracy 0.90651\n",
      "Loss changed.\n",
      "Epoch  49 | Training Loss 0.30834  | Test Loss 0.31308 |  Accuracy 0.90413\n",
      "No change in loss.\n",
      "Epoch  50 | Training Loss 0.30444  | Test Loss 0.30221 |  Accuracy 0.90762\n",
      "Loss changed.\n",
      "Epoch  51 | Training Loss 0.29555  | Test Loss 0.29903 |  Accuracy 0.90873\n",
      "Loss changed.\n",
      "Epoch  52 | Training Loss 0.29810  | Test Loss 0.28684 |  Accuracy 0.91476\n",
      "Loss changed.\n",
      "Epoch  53 | Training Loss 0.28601  | Test Loss 0.28724 |  Accuracy 0.91095\n",
      "No change in loss.\n",
      "Epoch  54 | Training Loss 0.28136  | Test Loss 0.28522 |  Accuracy 0.91556\n",
      "Loss changed.\n",
      "Epoch  55 | Training Loss 0.27380  | Test Loss 0.28121 |  Accuracy 0.91492\n",
      "Loss changed.\n",
      "Epoch  56 | Training Loss 0.26873  | Test Loss 0.26870 |  Accuracy 0.91397\n",
      "Loss changed.\n",
      "Epoch  57 | Training Loss 0.26641  | Test Loss 0.26412 |  Accuracy 0.92190\n",
      "Loss changed.\n",
      "Epoch  58 | Training Loss 0.25813  | Test Loss 0.26005 |  Accuracy 0.92079\n",
      "Loss changed.\n",
      "Epoch  59 | Training Loss 0.25634  | Test Loss 0.26139 |  Accuracy 0.92302\n",
      "No change in loss.\n",
      "Epoch  60 | Training Loss 0.25247  | Test Loss 0.25687 |  Accuracy 0.91889\n",
      "Loss changed.\n",
      "Epoch  61 | Training Loss 0.24936  | Test Loss 0.25495 |  Accuracy 0.92524\n",
      "Loss changed.\n",
      "Epoch  62 | Training Loss 0.24615  | Test Loss 0.24022 |  Accuracy 0.92730\n",
      "Loss changed.\n",
      "Epoch  63 | Training Loss 0.23866  | Test Loss 0.24414 |  Accuracy 0.92984\n",
      "No change in loss.\n",
      "Epoch  64 | Training Loss 0.23904  | Test Loss 0.23945 |  Accuracy 0.92778\n",
      "Loss changed.\n",
      "Epoch  65 | Training Loss 0.23584  | Test Loss 0.24120 |  Accuracy 0.92905\n",
      "No change in loss.\n",
      "Epoch  66 | Training Loss 0.23034  | Test Loss 0.24207 |  Accuracy 0.92698\n",
      "No change in loss.\n",
      "Epoch  67 | Training Loss 0.22309  | Test Loss 0.22843 |  Accuracy 0.93190\n",
      "Loss changed.\n",
      "Epoch  68 | Training Loss 0.22500  | Test Loss 0.22141 |  Accuracy 0.93476\n",
      "Loss changed.\n",
      "Epoch  69 | Training Loss 0.22021  | Test Loss 0.22448 |  Accuracy 0.93111\n",
      "No change in loss.\n",
      "Epoch  70 | Training Loss 0.22121  | Test Loss 0.21994 |  Accuracy 0.93603\n",
      "Loss changed.\n",
      "Epoch  71 | Training Loss 0.21599  | Test Loss 0.21506 |  Accuracy 0.93476\n",
      "Loss changed.\n",
      "Epoch  72 | Training Loss 0.21200  | Test Loss 0.22737 |  Accuracy 0.93190\n",
      "No change in loss.\n",
      "Epoch  73 | Training Loss 0.20949  | Test Loss 0.20881 |  Accuracy 0.93746\n",
      "Loss changed.\n",
      "Epoch  74 | Training Loss 0.21097  | Test Loss 0.21496 |  Accuracy 0.93857\n",
      "No change in loss.\n",
      "Epoch  75 | Training Loss 0.20688  | Test Loss 0.21529 |  Accuracy 0.93127\n",
      "No change in loss.\n",
      "Epoch  76 | Training Loss 0.20373  | Test Loss 0.21173 |  Accuracy 0.93778\n",
      "No change in loss.\n",
      "Epoch  77 | Training Loss 0.20459  | Test Loss 0.20890 |  Accuracy 0.93968\n",
      "No change in loss.\n",
      "Epoch  78 | Training Loss 0.19944  | Test Loss 0.19790 |  Accuracy 0.93873\n",
      "Loss changed.\n",
      "Epoch  79 | Training Loss 0.19441  | Test Loss 0.20243 |  Accuracy 0.93984\n",
      "No change in loss.\n",
      "Epoch  80 | Training Loss 0.19042  | Test Loss 0.19382 |  Accuracy 0.94238\n",
      "Loss changed.\n",
      "Epoch  81 | Training Loss 0.19221  | Test Loss 0.19157 |  Accuracy 0.94127\n",
      "Loss changed.\n",
      "Epoch  82 | Training Loss 0.18982  | Test Loss 0.18991 |  Accuracy 0.94206\n",
      "Loss changed.\n",
      "Epoch  83 | Training Loss 0.18938  | Test Loss 0.18950 |  Accuracy 0.94413\n",
      "Loss changed.\n",
      "Epoch  84 | Training Loss 0.18710  | Test Loss 0.19047 |  Accuracy 0.93968\n",
      "No change in loss.\n",
      "Epoch  85 | Training Loss 0.17901  | Test Loss 0.18589 |  Accuracy 0.94762\n",
      "Loss changed.\n",
      "Epoch  86 | Training Loss 0.17816  | Test Loss 0.19316 |  Accuracy 0.94111\n",
      "No change in loss.\n",
      "Epoch  87 | Training Loss 0.18004  | Test Loss 0.19044 |  Accuracy 0.94286\n",
      "No change in loss.\n",
      "Epoch  88 | Training Loss 0.17974  | Test Loss 0.18065 |  Accuracy 0.94540\n",
      "Loss changed.\n",
      "Epoch  89 | Training Loss 0.17752  | Test Loss 0.18513 |  Accuracy 0.94508\n",
      "No change in loss.\n",
      "Epoch  90 | Training Loss 0.17244  | Test Loss 0.17730 |  Accuracy 0.94762\n",
      "Loss changed.\n",
      "Epoch  91 | Training Loss 0.17274  | Test Loss 0.18053 |  Accuracy 0.94429\n",
      "No change in loss.\n",
      "Epoch  92 | Training Loss 0.16904  | Test Loss 0.17803 |  Accuracy 0.94556\n",
      "No change in loss.\n",
      "Epoch  93 | Training Loss 0.17223  | Test Loss 0.17976 |  Accuracy 0.94603\n",
      "No change in loss.\n",
      "Epoch  94 | Training Loss 0.16485  | Test Loss 0.17124 |  Accuracy 0.94873\n",
      "Loss changed.\n",
      "Epoch  95 | Training Loss 0.16622  | Test Loss 0.16796 |  Accuracy 0.95159\n",
      "Loss changed.\n",
      "Epoch  96 | Training Loss 0.16577  | Test Loss 0.17851 |  Accuracy 0.94635\n",
      "No change in loss.\n",
      "Epoch  97 | Training Loss 0.16486  | Test Loss 0.17902 |  Accuracy 0.94508\n",
      "No change in loss.\n",
      "Epoch  98 | Training Loss 0.16440  | Test Loss 0.16903 |  Accuracy 0.94921\n",
      "No change in loss.\n",
      "Epoch  99 | Training Loss 0.16389  | Test Loss 0.17211 |  Accuracy 0.94762\n",
      "No change in loss.\n",
      "Epoch 100 | Training Loss 0.16061  | Test Loss 0.16864 |  Accuracy 0.94905\n",
      "No change in loss.\n",
      "Terminating Model training, as there is no change in Loss.....\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "train_losses, valid_losses,valid_accuracy = [],[],[]\n",
    "early_stopping = EarlyStopper(patience=5)\n",
    "for e in range(epochs):\n",
    "    train_loss = train_per_epoch(train_loader,model,optimizer)\n",
    "    acc,valid_loss = test_per_epoch(valid_loader,model)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accuracy.append(acc)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {e+1:3} | Training Loss {train_loss/len(train_loader):.5f}  | Test Loss {valid_loss/len(valid_loader):.5f} | \",\n",
    "            f\"Accuracy {acc/len(valid_loader):.5f}\")\n",
    "\n",
    "    if early_stopping(valid_loss):\n",
    "        print(\"Terminating Model training, as there is no change in Loss.....\")\n",
    "        torch.save(model.state_dict(), os.path.join('notebooks',\"Model_Parameters.pt\"))\n",
    "        break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
